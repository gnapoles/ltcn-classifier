{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-term Cognitive Networks for pattern classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long-term Cognitive Networks are trained with an inverse learning rule. In this model, the weights connecting the input neurons are coefficients of multiple regressions models while the weights connecting the temporal states with and outputs are computed using a learning method (the Mooreâ€“Penrose inverse method when no regularization is needed or the Ridge regression method when the model might overfit the data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduces the results of the experiments reported in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import os\n",
    "\n",
    "from ltcnclassifier.LTCN import LTCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_random_seeds():\n",
    "    os.environ['PYTHONHASHSEED']=str(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "\n",
    "def kappa_scorer(Y_pred, Y):\n",
    "    return cohen_kappa_score(np.argmax(Y, axis=1), np.argmax(Y_pred, axis=1))\n",
    "\n",
    "def run_model(data, labels, n_classes, n_folds):\n",
    "    \n",
    "    reset_random_seeds()\n",
    "\n",
    "    X = data[:,:-n_classes]\n",
    "    Y = data[:,-n_classes:]\n",
    "    \n",
    "    train_errors = []\n",
    "    test_errors = []\n",
    "          \n",
    "    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    skf.get_n_splits(X, labels)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, labels):\n",
    "        \n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        Y_train, Y_test = Y[train_index], Y[test_index]\n",
    " \n",
    "        model = LTCN(method='inverse')\n",
    "\n",
    "        # hyper-parameter tuning using grid search happens here!!\n",
    "        param_grid = {'function': ['sigmoid', 'tanh'], 'phi': np.arange(0.5, 1.0, 0.1),\n",
    "                      'T': [5, 10, 15]} #  'alpha': [0, 1.0E-2, 1.0E+2]\n",
    "\n",
    "        kappa = make_scorer(kappa_scorer)\n",
    "        grid_clf = GridSearchCV(model, param_grid, scoring=kappa, cv=n_folds, n_jobs=-1, error_score='raise')\n",
    "        grid_clf.fit(X_train, Y_train)\n",
    "        \n",
    "        Y_pred_train = grid_clf.predict(X_train)\n",
    "        train_errors.append(cohen_kappa_score(np.argmax(Y_train, axis=1), np.argmax(Y_pred_train, axis=1)))\n",
    "        \n",
    "        Y_pred_test = grid_clf.predict(X_test)\n",
    "        test_errors.append(cohen_kappa_score(np.argmax(Y_test, axis=1), np.argmax(Y_pred_test, axis=1)))\n",
    "\n",
    "    return sum(train_errors) / len(train_errors), sum(test_errors) / len(test_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "files = os.listdir(os.pardir + '/datasets/')\n",
    "print(\"running...\")\n",
    "\n",
    "n_folds = 5\n",
    "\n",
    "# Input: A CSV file with normalized numerical values\n",
    "# The pre-processing consists of the following steps:\n",
    "#    1. We remove the classes whose number of instances is less than the number of folds\n",
    "#    2. We one-hot encode the decision classes since they have no ordinal relationship\n",
    "\n",
    "def preprocess(file):\n",
    "\n",
    "    df = pd.read_csv(os.pardir + '/datasets/' + file, header=None)\n",
    "\n",
    "    # select class values with at least n_folds ocurrences\n",
    "    serie = df[df.columns[-1]].value_counts() >= n_folds \n",
    "    l = serie.index[serie.values].tolist()        \n",
    "    df = df[df[df.columns[-1]].isin(l)]\n",
    "\n",
    "    df_features = df.iloc[:, :-1] # here we have the data values\n",
    "    df_classes = df.iloc[:, -1:] # here we have the classes\n",
    "\n",
    "    # we need to encode the decision classes\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore').fit(df_classes.values)\n",
    "\n",
    "    # use one-hot encode when no ordinal relationship exists\n",
    "    data_encoded = encoder.transform(df_classes.values).toarray()\n",
    "\n",
    "    # we have to merge the numerical variables with the encoded ones\n",
    "    # we put axis=1 to specify that the append will be by column\n",
    "    data = np.append(df_features.values, data_encoded, axis=1)\n",
    "\n",
    "    # we return the one-hot encoded dataset, the original classes for stratification\n",
    "    # in addition, we return the number of features and the number of unique classes\n",
    "\n",
    "    return data, df_classes.values, len(df_features.columns), len(np.unique(df_classes.values))\n",
    "\n",
    "with open('output.csv', 'a') as results_file:\n",
    "    \n",
    "    for file in files:\n",
    "        \n",
    "        if (not file.endswith('.csv')):\n",
    "            continue\n",
    "        \n",
    "        data, labels, n_features, n_classes = preprocess(file)\n",
    "        \n",
    "        train_kappa, test_kappa = run_model(data, labels, n_classes, n_folds)\n",
    "        results_file.write(file.replace('.csv', '') + \",\" + str(np.round(train_kappa, 4)) +\n",
    "                           \",\" + str(np.round(test_kappa, 4)) + \"\\n\")\n",
    "\n",
    "        results_file.flush()\n",
    "        print(file + ',' + str(np.round(train_kappa, 4)) + ',' + str(np.round(test_kappa, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}